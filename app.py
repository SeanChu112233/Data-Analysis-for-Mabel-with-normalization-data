import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import cross_val_score, ShuffleSplit
from mpl_toolkits.mplot3d import Axes3D
import plotly.graph_objects as go
import plotly.express as px

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ¨å‡ºåŠ›-æ¸©åº¦/æ—¶é—´æ¡ä»¶æ•°æ®åˆ†æå·¥å…· for Mabel",
    page_icon="ğŸ“Š",
    layout="wide"
)

# æ ‡é¢˜å’Œè¯´æ˜
st.title("ğŸ“Š æ¨å‡ºåŠ›-æ¸©åº¦/æ—¶é—´æ¡ä»¶æ•°æ®åˆ†æå·¥å…· for Mabel")
st.markdown("""
    è¯¥å·¥å…·ç”¨äºåˆ†ææ¸©åº¦(temp)ã€æ—¶é—´(time)ä¸æ¨å‡ºåŠ›(force)ä¹‹é—´çš„å…³ç³»ï¼Œ
    æ”¯æŒå¤šç§å›å½’æ¨¡å‹åˆ†æï¼Œå¹¶æä¾›å¯è§†åŒ–ç»“æœã€‚ç¨‹åºä¼šè‡ªåŠ¨å¯¹æ¯”æ•°æ®å½’ä¸€åŒ–å‰åçš„æ¨¡å‹è¡¨ç°ã€‚
    è¯·ä¸Šä¼ åŒ…å«ç›¸å…³æ•°æ®çš„CSVæ–‡ä»¶ã€‚
""")

# ä¾§è¾¹æ  - æ–‡ä»¶ä¸Šä¼ å’Œå‚æ•°è®¾ç½®
with st.sidebar:
    st.header("è®¾ç½®")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ•°æ®æ–‡ä»¶", type=["csv"])
    
    # æ¨¡å‹é€‰æ‹©
    model_option = st.selectbox(
        "é€‰æ‹©å›å½’æ¨¡å‹",
        ("éšæœºæ£®æ—", "æ¢¯åº¦æå‡æ ‘", "å¤šé¡¹å¼å›å½’", "çº¿æ€§å›å½’")
    )
    
    # æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
    st.subheader("æ•°æ®ä¿¡æ¯")
    data_info = st.empty()

# ä¸»ç¨‹åº
def main():
    # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†æ–‡ä»¶
    if uploaded_file is not None:
        try:
            # è¯»å–CSVæ–‡ä»¶
            data = pd.read_csv(uploaded_file)
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            required_columns = ['temp', 'time', 'force']
            data.columns = [col.lower() for col in data.columns]  # è½¬æ¢åˆ—åä¸ºå°å†™
            missing = [col for col in required_columns if col not in data.columns]
            
            if missing:
                st.error(f"æ•°æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦çš„åˆ—: {', '.join(missing)}")
                return
            
            # é‡å‘½ååˆ—åï¼Œé¦–å­—æ¯å¤§å†™
            data = data.rename(columns={
                'temp': 'Temp',
                'time': 'Time',
                'force': 'Force'
            })
            
            # åœ¨ä¾§è¾¹æ æ˜¾ç¤ºæ•°æ®ä¿¡æ¯
            with st.sidebar:
                data_info.dataframe(data.describe(), use_container_width=True)
                st.write(f"æ•°æ®é‡: {len(data)} æ¡")
            
            # æ˜¾ç¤ºåŸå§‹æ•°æ®
            with st.expander("æŸ¥çœ‹åŸå§‹æ•°æ®", expanded=False):
                st.dataframe(data, use_container_width=True)
            
            # å‡†å¤‡æ•°æ® - åŸå§‹å’Œå½’ä¸€åŒ–ç‰ˆæœ¬
            X_original = data[['Temp', 'Time']]
            y = data['Force']
            
            # æ•°æ®å½’ä¸€åŒ–
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X_original)
            X_scaled_df = pd.DataFrame(X_scaled, columns=['Temp', 'Time'])
            
            # æ˜¾ç¤ºå½’ä¸€åŒ–å‰åçš„æ•°æ®å¯¹æ¯”
            with st.expander("æŸ¥çœ‹å½’ä¸€åŒ–å‰åæ•°æ®å¯¹æ¯”", expanded=False):
                col1, col2 = st.columns(2)
                with col1:
                    st.subheader("åŸå§‹æ•°æ®")
                    st.dataframe(X_original.describe(), use_container_width=True)
                with col2:
                    st.subheader("å½’ä¸€åŒ–åæ•°æ®")
                    st.dataframe(X_scaled_df.describe(), use_container_width=True)
            
            # è®­ç»ƒæ¨¡å‹ - åŸå§‹å’Œå½’ä¸€åŒ–ä¸¤ç§ç‰ˆæœ¬
            models_original = train_models(X_original, y)
            models_scaled = train_models(X_scaled_df, y)
            
            # å¯¹æ¯”å½’ä¸€åŒ–å‰åçš„æ¨¡å‹æ€§èƒ½
            compare_normalization_effect(models_original, models_scaled, model_option)
            
            # é€‰æ‹©æ›´ä¼˜çš„æ¨¡å‹é›†
            best_version, best_models = select_better_version(models_original, models_scaled, model_option)
            st.success(f"åŸºäºäº¤å‰éªŒè¯RÂ²å€¼ï¼Œé€‰æ‹©{'å½’ä¸€åŒ–å' if best_version == 'scaled' else 'åŸå§‹æ•°æ®'}çš„æ¨¡å‹è¿›è¡Œåç»­åˆ†æ")
            
            # æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°ç»“æœ
            show_model_evaluation(best_models, data, best_version)
            
            # æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
            show_visualizations(best_models, data, model_option, best_version, scaler if best_version == 'scaled' else None)
            
            # äº¤äº’å¼é¢„æµ‹
            show_prediction_tool(best_models, data, model_option, best_version, scaler if best_version == 'scaled' else None)
            
        except Exception as e:
            st.error(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
    else:
        # æ˜¾ç¤ºç¤ºä¾‹æ•°æ®
        st.info("è¯·ä¸Šä¼ CSVæ–‡ä»¶å¼€å§‹åˆ†æã€‚ç¤ºä¾‹æ•°æ®æ ¼å¼å¦‚ä¸‹ï¼š")
        sample_data = pd.DataFrame({
            'temp': [70, 70, 70, 90, 90],
            'time': [60, 180, 300, 60, 180],
            'force': [3.4, 3.1, 3.3, 3.1, 2.8]
        })
        st.dataframe(sample_data, use_container_width=True)

def train_models(X, y):
    """è®­ç»ƒæ‰€æœ‰å›å½’æ¨¡å‹"""
    models = {}
    
    # 1. çº¿æ€§å›å½’
    linear_model = LinearRegression()
    linear_model.fit(X, y)
    models["çº¿æ€§å›å½’"] = {
        "model": linear_model,
        "type": "linear"
    }
    
    # 2. å¤šé¡¹å¼å›å½’ (äºŒæ¬¡é¡¹)
    poly = PolynomialFeatures(degree=2, include_bias=False)
    X_poly = poly.fit_transform(X)
    poly_model = LinearRegression()
    poly_model.fit(X_poly, y)
    models["å¤šé¡¹å¼å›å½’"] = {
        "model": poly_model,
        "type": "polynomial",
        "poly_transform": poly
    }
    
    # 3. éšæœºæ£®æ—å›å½’
    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
    rf_model.fit(X, y)
    models["éšæœºæ£®æ—"] = {
        "model": rf_model,
        "type": "nonlinear"
    }
    
    # 4. æ¢¯åº¦æå‡æ ‘å›å½’
    gb_model = GradientBoostingRegressor(
        n_estimators=30,        # å‡å°‘æ ‘çš„æ•°é‡
        max_depth=3,            # é™åˆ¶æ ‘æ·±åº¦
        min_samples_leaf=2,     # å¢åŠ å¶èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
        subsample=0.8,          # ä½¿ç”¨80%çš„æ ·æœ¬è®­ç»ƒæ¯æ£µæ ‘
        random_state=42
    )
    gb_model.fit(X, y)
    models["æ¢¯åº¦æå‡æ ‘"] = {
        "model": gb_model,
        "type": "nonlinear"
    }
    
    # è¯„ä¼°æ¨¡å‹
    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)
    for name, model_info in models.items():
        model = model_info["model"]
        
        if model_info["type"] == "polynomial":
            X_processed = model_info["poly_transform"].transform(X)
        else:
            X_processed = X
        
        # è®¡ç®—äº¤å‰éªŒè¯å¾—åˆ†
        cv_scores = cross_val_score(model, X_processed, y, cv=cv, scoring='r2')
        cv_rmse = cross_val_score(model, X_processed, y, cv=cv, scoring='neg_mean_squared_error')
        
        # è®¡ç®—è®­ç»ƒRÂ²å’ŒRMSE
        y_pred = predict_with_model(name, models, X)
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        
        model_info["cv_r2_mean"] = np.mean(cv_scores)
        model_info["cv_r2_std"] = np.std(cv_scores)
        model_info["cv_rmse_mean"] = np.mean(np.sqrt(-cv_rmse))
        model_info["train_r2"] = r2
        model_info["train_rmse"] = rmse
    
    return models

def predict_with_model(model_name, models, X):
    """ä½¿ç”¨æŒ‡å®šæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
    model_info = models[model_name]
    model = model_info["model"]
    
    if model_info["type"] == "polynomial":
        X_processed = model_info["poly_transform"].transform(X)
        return model.predict(X_processed)
    else:
        return model.predict(X)

def compare_normalization_effect(models_original, models_scaled, selected_model):
    """å¯¹æ¯”å½’ä¸€åŒ–å‰åçš„æ¨¡å‹æ€§èƒ½"""
    st.subheader("ğŸ“Š å½’ä¸€åŒ–å‰åæ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    
    # å‡†å¤‡å¯¹æ¯”æ•°æ®
    compare_data = []
    
    # å¯¹æ¯”æ‰€é€‰æ¨¡å‹
    orig_info = models_original[selected_model]
    scaled_info = models_scaled[selected_model]
    
    compare_data.append({
        "è¯„ä¼°æŒ‡æ ‡": "è®­ç»ƒRÂ²",
        "åŸå§‹æ•°æ®": f"{orig_info['train_r2']:.4f}",
        "å½’ä¸€åŒ–å": f"{scaled_info['train_r2']:.4f}",
        "å˜åŒ–": f"{(scaled_info['train_r2'] - orig_info['train_r2']):+.4f}"
    })
    
    compare_data.append({
        "è¯„ä¼°æŒ‡æ ‡": "äº¤å‰éªŒè¯RÂ²",
        "åŸå§‹æ•°æ®": f"{orig_info['cv_r2_mean']:.4f}",
        "å½’ä¸€åŒ–å": f"{scaled_info['cv_r2_mean']:.4f}",
        "å˜åŒ–": f"{(scaled_info['cv_r2_mean'] - orig_info['cv_r2_mean']):+.4f}"
    })
    
    compare_data.append({
        "è¯„ä¼°æŒ‡æ ‡": "è®­ç»ƒRMSE",
        "åŸå§‹æ•°æ®": f"{orig_info['train_rmse']:.4f}",
        "å½’ä¸€åŒ–å": f"{scaled_info['train_rmse']:.4f}",
        "å˜åŒ–": f"{(scaled_info['train_rmse'] - orig_info['train_rmse']):+.4f}"
    })
    
    compare_df = pd.DataFrame(compare_data)
    
    # é«˜äº®æ˜¾ç¤ºæ›´å¥½çš„ç»“æœ
    def highlight_better(row):
        styles = []
        metric = row['è¯„ä¼°æŒ‡æ ‡']
        orig_val = float(row['åŸå§‹æ•°æ®'])
        scaled_val = float(row['å½’ä¸€åŒ–å'])
        
        for col in row.index:
            if col == 'åŸå§‹æ•°æ®':
                # RÂ²è¶Šå¤§è¶Šå¥½ï¼ŒRMSEè¶Šå°è¶Šå¥½
                if (metric.endswith('RÂ²') and orig_val > scaled_val) or \
                   (metric.endswith('RMSE') and orig_val < scaled_val):
                    styles.append('background-color: #90EE90')
                else:
                    styles.append('')
            elif col == 'å½’ä¸€åŒ–å':
                if (metric.endswith('RÂ²') and scaled_val > orig_val) or \
                   (metric.endswith('RMSE') and scaled_val < orig_val):
                    styles.append('background-color: #90EE90')
                else:
                    styles.append('')
            else:
                styles.append('')
        return styles
    
    styled_df = compare_df.style.apply(highlight_better, axis=1)
    st.dataframe(styled_df, use_container_width=True)

def select_better_version(models_original, models_scaled, selected_model):
    """é€‰æ‹©æ€§èƒ½æ›´å¥½çš„æ¨¡å‹ç‰ˆæœ¬ï¼ˆåŸå§‹æˆ–å½’ä¸€åŒ–ï¼‰"""
    orig_score = models_original[selected_model]['cv_r2_mean']
    scaled_score = models_scaled[selected_model]['cv_r2_mean']
    
    # å¦‚æœå½’ä¸€åŒ–åäº¤å‰éªŒè¯RÂ²æ›´é«˜ï¼Œåˆ™é€‰æ‹©å½’ä¸€åŒ–ç‰ˆæœ¬
    if scaled_score > orig_score:
        return 'scaled', models_scaled
    else:
        return 'original', models_original

def show_model_evaluation(models, data, version):
    """æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°ç»“æœ"""
    st.subheader(f"ğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ ({'å½’ä¸€åŒ–å' if version == 'scaled' else 'åŸå§‹æ•°æ®'})")
    
    # å‡†å¤‡è¯„ä¼°ç»“æœæ•°æ®
    eval_data = []
    for name, info in models.items():
        eval_data.append({
            "æ¨¡å‹": name,
            "è®­ç»ƒRÂ²": f"{info['train_r2']:.4f}",
            "äº¤å‰éªŒè¯RÂ²": f"{info['cv_r2_mean']:.4f} Â± {info['cv_r2_std']:.4f}",
            "è®­ç»ƒRMSE": f"{info['train_rmse']:.4f}"
        })
    
    eval_df = pd.DataFrame(eval_data)
    
    # æ‰¾å‡ºæœ€ä½³æ¨¡å‹ï¼ˆäº¤å‰éªŒè¯RÂ²æœ€é«˜ï¼‰
    best_model = max(models.items(), key=lambda x: x[1]["cv_r2_mean"])[0]
    
    # æ˜¾ç¤ºè¯„ä¼°è¡¨æ ¼ï¼Œçªå‡ºæœ€ä½³æ¨¡å‹
    def highlight_best(row):
        return ['background-color: #90EE90' if row['æ¨¡å‹'] == best_model else '' for _ in row]
    
    styled_df = eval_df.style.apply(highlight_best, axis=1)
    st.dataframe(styled_df, use_container_width=True)
    
    st.info(f"æ¨èæ¨¡å‹: **{best_model}** (åŸºäºäº¤å‰éªŒè¯RÂ²æœ€é«˜)")

def show_visualizations(models, data, model_name, version, scaler):
    """æ˜¾ç¤ºæ•°æ®å¯è§†åŒ–ç»“æœ"""
    st.subheader("ğŸ” æ•°æ®å¯è§†åŒ–")
    
    # åˆ›å»ºç½‘æ ¼æ•°æ®ç”¨äºç»˜åˆ¶æ›²é¢
    x = data['Temp']
    y = data['Time']
    z = data['Force']
    
    x_range = np.linspace(x.min(), x.max(), 30)
    y_range = np.linspace(y.min(), y.max(), 30)
    X_grid, Y_grid = np.meshgrid(x_range, y_range)
    grid_data = np.column_stack([X_grid.ravel(), Y_grid.ravel()])
    
    # å¦‚æœä½¿ç”¨å½’ä¸€åŒ–æ¨¡å‹ï¼Œéœ€è¦å¯¹ç½‘æ ¼æ•°æ®è¿›è¡Œå½’ä¸€åŒ–
    if version == 'scaled' and scaler is not None:
        grid_data_scaled = scaler.transform(grid_data)
        grid_data_processed = pd.DataFrame(grid_data_scaled, columns=['Temp', 'Time'])
    else:
        grid_data_processed = pd.DataFrame(grid_data, columns=['Temp', 'Time'])
    
    # è·å–æ¨¡å‹é¢„æµ‹å€¼
    Z_grid = predict_with_model(model_name, models, grid_data_processed)
    Z_grid = Z_grid.reshape(X_grid.shape)
    
    # åˆ†ä¸ºä¸¤åˆ—æ˜¾ç¤ºå›¾è¡¨
    col1, col2 = st.columns(2)
    
    with col1:
        # 3Dæ•£ç‚¹å›¾å’Œæ›²é¢å›¾ (ä½¿ç”¨plotly)
        st.subheader(f"3Då…³ç³»å›¾ ({model_name})")
        
        # åˆ›å»º3Då›¾å½¢
        fig = go.Figure()
        
        # æ·»åŠ åŸå§‹æ•°æ®ç‚¹
        fig.add_trace(go.Scatter3d(
            x=x, y=y, z=z,
            mode='markers',
            marker=dict(size=5, color='red'),
            name='å®éªŒæ•°æ®'
        ))
        
        # æ·»åŠ é¢„æµ‹æ›²é¢
        fig.add_trace(go.Surface(
            x=X_grid, y=Y_grid, z=Z_grid,
            opacity=0.6,
            colorscale='Viridis',
            name='é¢„æµ‹æ›²é¢'
        ))
        
        fig.update_layout(
            scene=dict(
                xaxis_title='æ¸©åº¦ (Â°C)',
                yaxis_title='æ—¶é—´ (s)',
                zaxis_title='æ¨å‡ºåŠ›'
            ),
            height=500
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # çƒ­åŒºå›¾
        st.subheader(f"çƒ­åŒºå›¾ ({model_name})")
        
        # åˆ›å»ºçƒ­åŒºå›¾æ•°æ®
        z_dense = Z_grid
        fig = px.imshow(
            z_dense,
            x=x_range,
            y=y_range,
            color_continuous_scale='Viridis',
            aspect='auto',
            labels=dict(x="æ¸©åº¦ (Â°C)", y="æ—¶é—´ (s)", color="æ¨å‡ºåŠ›")
        )
        
        # æ·»åŠ åŸå§‹æ•°æ®ç‚¹
        fig.add_scatter(x=x, y=y, mode='markers', 
                       marker=dict(color='red', size=8, line=dict(width=2, color='black')),
                       name='å®éªŒæ•°æ®')
        
        fig.update_layout(height=500)
        st.plotly_chart(fig, use_container_width=True)
    
    # ç›¸å…³æ€§åˆ†æ
    st.subheader("ğŸ“Š ç›¸å…³æ€§åˆ†æ")
    corr = data.corr()
    fig, ax = plt.subplots(figsize=(8, 6))
    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)
    st.pyplot(fig)

def show_prediction_tool(models, data, model_name, version, scaler):
    """æ˜¾ç¤ºäº¤äº’å¼é¢„æµ‹å·¥å…·"""
    st.subheader("ğŸ”® æ¨å‡ºåŠ›é¢„æµ‹")
    
    # è·å–æ•°æ®èŒƒå›´
    temp_min, temp_max = data['Temp'].min(), data['Temp'].max()
    time_min, time_max = data['Time'].min(), data['Time'].max()
    
    # æ·»åŠ ä¸€äº›ç¼“å†²
    temp_buffer = (temp_max - temp_min) * 0.1
    time_buffer = (time_max - time_min) * 0.1
    
    # åˆ›å»ºè¾“å…¥æ§ä»¶
    col1, col2 = st.columns(2)
    
    with col1:
        temp = st.slider(
            "æ¸©åº¦ (Â°C)",
            min_value=float(temp_min - temp_buffer),
            max_value=float(temp_max + temp_buffer),
            value=float(data['Temp'].mean())
        )
    
    with col2:
        time = st.slider(
            "æ—¶é—´ (s)",
            min_value=float(time_min - time_buffer),
            max_value=float(time_max + time_buffer),
            value=float(data['Time'].mean())
        )
    
    # å‡†å¤‡é¢„æµ‹æ•°æ®
    X_pred = pd.DataFrame([[temp, time]], columns=['Temp', 'Time'])
    
    # å¦‚æœä½¿ç”¨å½’ä¸€åŒ–æ¨¡å‹ï¼Œéœ€è¦å¯¹è¾“å…¥æ•°æ®è¿›è¡Œå½’ä¸€åŒ–
    if version == 'scaled' and scaler is not None:
        X_pred_scaled = scaler.transform(X_pred)
        X_pred_processed = pd.DataFrame(X_pred_scaled, columns=['Temp', 'Time'])
    else:
        X_pred_processed = X_pred
    
    # é¢„æµ‹æ¨å‡ºåŠ›
    force_pred = predict_with_model(model_name, models, X_pred_processed)[0]
    
    # æ˜¾ç¤ºé¢„æµ‹ç»“æœ
    st.metric("é¢„æµ‹æ¨å‡ºåŠ›", f"{force_pred:.4f}", delta=None)
    
    # æ˜¾ç¤ºæ¨¡å‹å½±å“åˆ†æ
    st.subheader("ğŸ“‹ å½±å“åˆ†æ")
    model_info = models[model_name]
    
    if model_name == "çº¿æ€§å›å½’":
        coefs = model_info["model"].coef_
        intercept = model_info["model"].intercept_
        
        if version == 'scaled':
            st.info("æ³¨æ„ï¼šå½’ä¸€åŒ–åçš„çº¿æ€§å›å½’ç³»æ•°ä¸èƒ½ç›´æ¥æ¯”è¾ƒåŸå§‹ç‰¹å¾çš„å½±å“å¤§å°ï¼Œå› ä¸ºç‰¹å¾å·²è¢«æ ‡å‡†åŒ–")
            st.latex(f"æ¨å‡ºåŠ› = {intercept:.4f} + {coefs[0]:.4f} \\times æ ‡å‡†åŒ–æ¸©åº¦ + {coefs[1]:.4f} \\times æ ‡å‡†åŒ–æ—¶é—´")
        else:
            st.latex(f"æ¨å‡ºåŠ› = {intercept:.4f} + {coefs[0]:.4f} \\times æ¸©åº¦ + {coefs[1]:.4f} \\times æ—¶é—´")
        
        st.write(f"å†³å®šç³»æ•° RÂ²: {model_info['train_r2']:.4f}")
        
        # åˆ†æå½±å“å¤§å°ï¼ˆä»…å¯¹åŸå§‹æ•°æ®æœ‰æ„ä¹‰ï¼‰
        if version != 'scaled':
            temp_impact = abs(coefs[0])
            time_impact = abs(coefs[1])
            
            if temp_impact > time_impact:
                st.info(f"æ¸©åº¦å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (å½±å“æ¯”ä¾‹: {temp_impact/time_impact:.2f}:1)")
            elif time_impact > temp_impact:
                st.info(f"æ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (å½±å“æ¯”ä¾‹: 1:{time_impact/temp_impact:.2f})")
            else:
                st.info("æ¸©åº¦å’Œæ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“å¤§è‡´ç›¸åŒ")
    
    elif model_name == "å¤šé¡¹å¼å›å½’":
        st.write(f"å†³å®šç³»æ•° RÂ²: {model_info['train_r2']:.4f}")
        if version == 'scaled':
            st.info("æ¨¡å‹åŒ…å«æ ‡å‡†åŒ–æ¸©åº¦ã€æ ‡å‡†åŒ–æ—¶é—´çš„äºŒæ¬¡é¡¹ä»¥åŠäº¤äº’é¡¹ï¼Œè¡¨æ˜å®ƒä»¬å¯¹æ¨å‡ºåŠ›çš„å½±å“æ˜¯éçº¿æ€§çš„")
        else:
            st.info("æ¨¡å‹åŒ…å«æ¸©åº¦ã€æ—¶é—´çš„äºŒæ¬¡é¡¹ä»¥åŠäº¤äº’é¡¹ï¼Œè¡¨æ˜å®ƒä»¬å¯¹æ¨å‡ºåŠ›çš„å½±å“æ˜¯éçº¿æ€§çš„ï¼Œåœ¨ä¸åŒèŒƒå›´å†…å½±å“ç¨‹åº¦ä¸åŒ")
    
    else:  # éšæœºæ£®æ—å’Œæ¢¯åº¦æå‡æ ‘
        st.write(f"å†³å®šç³»æ•° RÂ²: {model_info['train_r2']:.4f}")
        
        # ç‰¹å¾é‡è¦æ€§
        importances = model_info["model"].feature_importances_
        temp_importance = importances[0]
        time_importance = importances[1]
        
        st.write(f"æ¸©åº¦ç‰¹å¾é‡è¦æ€§: {temp_importance:.4f}")
        st.write(f"æ—¶é—´ç‰¹å¾é‡è¦æ€§: {time_importance:.4f}")
        
        if temp_importance > time_importance:
            st.info(f"æ¸©åº¦å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (é‡è¦æ€§æ¯”ä¾‹: {temp_importance/time_importance:.2f}:1)")
        elif time_importance > temp_importance:
            st.info(f"æ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“æ›´å¤§ (é‡è¦æ€§æ¯”ä¾‹: 1:{time_importance/temp_importance:.2f})")
        else:
            st.info("æ¸©åº¦å’Œæ—¶é—´å¯¹æ¨å‡ºåŠ›çš„å½±å“å¤§è‡´ç›¸åŒ")

# æ·»åŠ é¡µè„šä¿¡æ¯
def add_footer():
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center;">
        <p>å›¢é˜Ÿè´¡çŒ®æ•°æ®åˆ†æå·¥å…· | æ•°æ®æ¥æºäºä¸Šä¼ çš„CSVæ–‡ä»¶</p>
        <p>Â© 2023 å›¢é˜Ÿè´¡çŒ®åˆ†æé¡¹ç›®</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
    add_footer()
